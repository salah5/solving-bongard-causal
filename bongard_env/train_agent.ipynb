{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb211c6b",
   "metadata": {},
   "source": [
    "# Example for training an agent on the Bongard environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599eecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from bongard_base_env import BPEnv\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from eval_model import eval_model, dict_to_runname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902725a",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_dict = {'PPO': PPO, 'A2C': A2C}\n",
    "env_dict = {'BPEnv': BPEnv}\n",
    "\n",
    "params = {\n",
    "\n",
    "    'env': 'BPEnv', # Environment for training the agent\n",
    "    'algo': 'PPO', # Algorithm used for training\n",
    "    'policy': 'SiaMlpPolicy', # Network architecture for policy\n",
    "    'lr': 7e-05, # Learning rate\n",
    "    'eplength': False, # Episode length\n",
    "    'CB': False, # Causal Bounds\n",
    "    'clip_range': 0.2, # PPO clipping range\n",
    "    'save_model': False, # Whether to save model or not\n",
    "    'run_name' : '', # Runname for saving model, if empty name will be generated from parameters\n",
    "    'seeds':  [11, 61, 331], # Random seeds to train on\n",
    "    'log_dir': 'logs/', # Log directory used for tensorboard logs\n",
    "    'total_timesteps': 2000000, # Total timesteps for training\n",
    "    'skip_action' : True, # Whether to include skip action or not (not at the same time with CB)\n",
    "    'test_mode': False, # Testing mode for agent\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ba66d",
   "metadata": {},
   "source": [
    "## Initialize Environment\n",
    "In the case of BP environments we have the option of including the skip action or leaving it out which can be specified in the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ae4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_dict[params['env']](skip_action=params['skip_action'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84aecbc",
   "metadata": {},
   "source": [
    "## Train the agent\n",
    "We train the agent for several random seeds which can also be set in the hyperparameters. The name of the run which will be used for saving logs and the trained model can be specified in the hyperparameters and if no name is specified, a name will be generated based on the settings for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be00c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in params['seeds']:\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    params['seed'] = seed\n",
    "    params['run_name'] = dict_to_runname(params)\n",
    "    algo = algo_dict[params['algo']](params['policy'], env, learning_rate=params['lr'], clip_range=params['clip_range'], verbose=1, causal=params['CB'], tensorboard_log=f\"./{params['log_dir']}{params['run_name']}/\")\n",
    "\n",
    "    algo.learn(total_timesteps=params['total_timesteps'], tb_log_name=f\"{params['run_name']}\")\n",
    "    algo.save(params['run_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bongard",
   "language": "python",
   "name": "bongard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
